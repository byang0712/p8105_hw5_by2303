---
title: "Homework 5"
author: "Bin Yang"
date: "11/10/2020"
output: github_document
---
```{r}
library(tidyverse)
library(rvest)
knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)
theme_set(theme_minimal() + theme(legend.position = "bottom"))
options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)
scale_colour_discrete = scale_color_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

## Problem 1 
```{r, error = TRUE}
city_prop_test = function(df) {
  
  n_unsolved 
  n_total 
  
  prop.test(...)
}


homicide_df = 
  read_csv("./data/homicide-data.csv") %>% 
  mutate(
    city_state = str_c(city, state, sep = "_"),
    resolved = case_when(
      disposition == "Closed by arrest" ~ "unsolved", 
      disposition == "Closed without arrest" ~ "unsolved",
      disposition == "Open/No arrest" ~ "solved"
    )
  ) %>% 
  select(city_state, resolved) %>% 
  filter(city_state != "Tulsa_AL") 
``` 


```{r}
aggregate_df = 
  homicide_df %>% 
  group_by(city_state) %>% 
  summarize(
    hom_total = n(),
    hom_unsolved = sum(resolved == "unsolved")
  ) 
```


```{r}
prop.test(
  aggregate_df %>% filter(city_state == "Baltimore_MD") %>% pull(hom_unsolved), 
  aggregate_df %>% filter(city_state == "Baltimore_MD") %>% pull(hom_total)) %>% 
  broom::tidy()
  
```

iteration:  

```{r}
results_df =
  aggregate_df %>% 
  mutate(
    prop_tests = map2(.x = hom_unsolved, .y = hom_total, ~prop.test(x = .x, n = .y)),
    tidy_tests = map(.x = prop_tests, ~broom::tidy(.x))
  ) %>% 
  select(-prop_tests) %>% 
  unnest(tidy_tests) %>% 
  select(city_state, estimate, conf.low, conf.high)
```

```{r}
results_df %>% 
  mutate(city_state = fct_reorder(city_state, estimate)) %>% 
  ggplot(aes(x = city_state, y = estimate)) +
  geom_point() + 
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high)) +
  theme(axis.text.x = element_text(angle = 270, vjust = 0.5, hjust=1))
```

## Problem 2 
  
Read in and tidy the datasets:
  
```{r}
lgt_df = 
  tibble(
  path = list.files("./data/p2")
) %>% 
  mutate(path = str_c("./data/p2/", path),
         data = map(.x = path, ~read_csv(.x)),
         path2 = list.files("./data/p2")) %>%
  separate(path2, c("group", "id")) %>% 
  unnest() %>% 
  select(id, group, everything()) %>% 
  select(-path) %>% 
  pivot_longer(
    week_1:week_8,
    names_to = "week",
    values_to = "observations"
  )
```
  
A spaghetti plot showing observations on each subject over time:   

```{r}
group_name = list(
  `con` = "control_group",
  `exp` = "experiment_group"
)

group_labeller = function(variable, value){
  return(group_name[value])
}
  
  
lgt_df %>% 
  mutate(id = as.factor(id),
         week = as.factor(week)) %>% 
  ggplot(aes(x = week, y = observations, group = id)) +
  geom_line(aes(color = id)) +
  facet_grid(.~group, labeller = group_labeller) +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) + 
  labs(
    title = "Spaghetti Plot", 
    x = "Week",
    y = "Observation"
  )

```
As we can see from the plot, observations in control group are showing a slight downward trend or fluctuating in the approximately same range during the study period; while observations in experiment groups are showing a upward trend in the study period. 

## Problem 3  

#### create simulation data

```{r}
#data generating function 
sim_data_fn = function(samp_size, mu = 0, sigma = 5) {
  
  sim_data = 
    tibble(
      x = rnorm(n = samp_size, mean = mu, sd = sigma)
    )
}

# simulation results
set.seed(1234) 

sim_results = 
  tibble(mu = c(0,1,2,3,4,5,6)) %>% 
  mutate(
  output_lists = map(.x = mu, ~rerun(5000, sim_data_fn(30, mu = .x)))
        ) %>% 
  unnest() %>% 
  mutate(
    t_tests = map(.x = output_lists, ~t.test(x = .x, mu = 0, conf.level = 0.95)),
    tidy_tests = map(.x = t_tests, ~broom::tidy(.x))
         ) %>% 
  unnest(tidy_tests) %>% 
  select(mu, estimate, p.value)
```

#### make plot  

* A plot showing the proportion of times the null was rejected (the power of the test) on the *y* axis and the true value of $\beta_1$ on the *x* axis.

```{r}
sim_results %>% 
  group_by(mu) %>%
  summarise(
    p_sum = sum(p.value < 0.05),
    count = n(),
    p_prop = p_sum/count
  ) %>% 
  ggplot(aes(x = mu, y = p_prop)) +
  geom_point() +
  labs(
    title = "Plot for Effect Size and Power",
    x = "true mean",
    y = "power of test"
  )
```
  
comments: For any given population standard deviation, the greater the difference between the means of the null and alternative distributions, the greater the power.  

* A plot showing the average estimate of $\hat{\mu}$ on the *y* axis and the true value of $\mu$ on the *x* axis:

```{r}
sim_results %>% 
  group_by(mu) %>% 
  summarise(
    average_est = mean(estimate)
  ) %>% 
  ggplot(aes(x = mu, y = average_est)) +
  geom_point() +
  geom_line()+
  labs(
    x = "true mean",
    y = "average estimate mean"
  ) 
``` 
  
* A plot showing the average estimate of $\hat{\mu}$ on the *y* axis and the true value of $\mu$ on the *x* axis only in samples for which the null was rejected:  

```{r}
overall_df = 
  sim_results %>% 
  group_by(mu) %>% 
  summarise(
    average_est = mean(estimate)
  ) 

sim_results %>% 
  filter(p.value < 0.05) %>% 
  group_by(mu) %>% 
  summarise(
    average_est =  mean(estimate)
  ) %>% 
  ggplot(aes(x = mu, y = average_est)) +
  geom_point() +
  geom_line() + 
  geom_point(data = overall_df) +
  geom_line(data = overall_df, aes(x = mu, y = average_est), color = "red") + 
  labs(
    x = "true mean",
    y = "average estimate mean"
  )
  
```
comments:  We can see that sample average of mu hat across tests for which the null is rejected is close to true mean for mu = 4,5 and 6; while for mu = 0, 1, 2, and 3, sample average of mu hat is significantly different from the true mean. We reject the null hypothesis when the estimate is significantly different from 0. Therefore for samples where mu is close to 0 (mu = 0, 1, 2, and 3), the average estimated mean will generally be larger than the true mean and for samples where mu is much larger than 0 (mu = 4, 5, 6), the average estimated mean will be approximately equal to the true mean. 
